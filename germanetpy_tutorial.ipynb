{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PyGermanet Tutorial\n",
    "\n",
    "The following tutorial shows some examples of how to use the Python API for Germanet. Germanet is a lexical-sematic \n",
    "net that relates German nouns, verbs and adjectives semantically by grouping lexical units that express\n",
    "the same concept into synsets. \n",
    "\n",
    "With the Python API we can extract synsets and lexical units for a given word and inspect different properties and related\n",
    "synsets / lexunits. To use the API you can install it with pip:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: germanetpy in /Users/nwitte/PycharmProjects/germanetpy (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from germanetpy) (1.18.1)\n",
      "Requirement already satisfied: lxml>=4.4.2 in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from germanetpy) (4.4.2)\n",
      "Requirement already satisfied: pytest>=5.3.2 in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from germanetpy) (5.4.1)\n",
      "Requirement already satisfied: fastenum>=0.0.1 in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from germanetpy) (0.0.1)\n",
      "Requirement already satisfied: tqdm>=4.14 in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from germanetpy) (4.41.1)\n",
      "Requirement already satisfied: python-Levenshtein==0.12.0 in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from germanetpy) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from pytest>=5.3.2->germanetpy) (1.4.0)\n",
      "Requirement already satisfied: wcwidth in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from pytest>=5.3.2->germanetpy) (0.1.8)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from pytest>=5.3.2->germanetpy) (19.3.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from pytest>=5.3.2->germanetpy) (1.8.1)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from pytest>=5.3.2->germanetpy) (8.1.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from pytest>=5.3.2->germanetpy) (0.13.1)\n",
      "Requirement already satisfied: packaging in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from pytest>=5.3.2->germanetpy) (20.0)\n",
      "Requirement already satisfied: setuptools in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages/setuptools-40.8.0-py3.7.egg (from python-Levenshtein==0.12.0->germanetpy) (40.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->germanetpy) (1.0.0)\n",
      "Requirement already satisfied: six in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from packaging->pytest>=5.3.2->germanetpy) (1.13.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/nwitte/.virtualenvs/germanetpy/lib/python3.7/site-packages (from packaging->pytest>=5.3.2->germanetpy) (2.4.6)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install germanetpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from germanetpy.germanet import Germanet\n",
    "from germanetpy.frames import Frames\n",
    "from germanetpy.filterconfig import Filterconfig\n",
    "from germanetpy.synset import WordCategory, WordClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Whenever you want to use the API, the first thing you would do is to create a GermaNet object as this loads the data and provides access to it. The data (all XML files) have to be stored in one directory which has to be specified as the first argument when you construct the GermaNet object. If you want to run this code, put your XML files in a \"germanet_data\" directory in your home directory or change the path to the location on your computer. The API also provides methods to compute semantic similarity / relatedness between words (Synsets). To be able to use all of them you have to provide frequency lists for each word category. These lists can be downloaded from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load GermaNet data...: 100%|█████████▉| 99.99999999999996/100 [00:08<00:00, 12.27it/s] \n",
      "Load Wictionary data...: 100%|██████████| 100.0/100 [00:00<00:00, 257.84it/s]             \n",
      "Load Ili records...: 100%|██████████| 100.0/100 [00:00<00:00, 282.78it/s]\n"
     ]
    }
   ],
   "source": [
    "userHome = str(Path.home())\n",
    "data_path = userHome + \"/germanet_data\"\n",
    "frequencylist_nouns = data_path + \"/noun_freqs_decow14_16.txt\"\n",
    "germanet = Germanet(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "The data has been loaded and we can now use the API to extract specific information from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## How to inspect information for a single word input\n",
    "\n",
    "### Inspect synsets\n",
    "\n",
    "Let's consider the input word *Fußball* 'football'. The following shows how to extract all synsets given an input wordform.\n",
    "Many words are ambiguous and thus, *Fußball* belongs to two synsets. The string representations include the lexical units, which can be helpful when you want to select\n",
    "a specific meaning for a given word. In this case, let's say we are interested in the second meaning of\n",
    "*Fußball*, namely the game and not the ball.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input has 2 senses \n",
      "Synset(id=s21624, lexunits=Fußballspiel, Fußball, Fußballsport)\n",
      "Synset(id=s7944, lexunits=Fußball)\n"
     ]
    }
   ],
   "source": [
    "fussball_synsets = germanet.get_synsets_by_orthform(\"Fußball\")\n",
    "# the lengths of the retrieved list is equal to the number of possible senses for a word, in this case 2\n",
    "print(\"The input has %d senses \" % len(fussball_synsets))\n",
    "for synset in fussball_synsets:\n",
    "    print(synset)\n",
    "fussball_synset = germanet.get_synset_by_id('s21624')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Every synset has a number of properties that can be extracted. Each synset has a unique id, which is the character\n",
    "'s' followed by a number. A synset can have one of three possible word categories (verb, noun, adjective). \n",
    "For each of the word categories the semantic space is divided into a number of semantic fields. (e.g *Besitz*,\n",
    "*Kommunikation*, *Geschehen*...), called word_class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The synset id is s21624; the synset belongs to the word category WordCategory.nomen \n",
      " and to the semantic field WordClass.Geschehen.\n"
     ]
    }
   ],
   "source": [
    "id = fussball_synset.id\n",
    "word_category = fussball_synset.word_category\n",
    "semantic_field = fussball_synset.word_class\n",
    "print(\"The synset id is %s; the synset belongs to the word category %s \\n and to the semantic field %s.\" %\n",
    "      (id, word_category, semantic_field))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Synsets are related to other synsets via conceptual relations. The most important relation is the hypernymy\n",
    "/ hyponymy relation. Direct hypernyms of a synset (one level above) and hyponyms (one level below) can be accessed through a separate field, all conceptually related \n",
    "synsets are stored in the relations field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Synset(id=s21606, lexunits=Ballspiel, Ballsport, Ballsportart)}\n",
      "{Synset(id=s84590, lexunits=Männerfußball), Synset(id=s104374, lexunits=Spitzenfußball), Synset(id=s69685, lexunits=Amateurfußball), Synset(id=s137475, lexunits=Klubfußball), Synset(id=s139802, lexunits=Torwandschießen), Synset(id=s124051, lexunits=Freizeitfußball), Synset(id=s146603, lexunits=Straßenfußball), Synset(id=s21626, lexunits=Frauenfußball, Damenfußball), Synset(id=s79925, lexunits=Hallenfußball), Synset(id=s133731, lexunits=Weltfußball), Synset(id=s145820, lexunits=Kombinationsfußball), Synset(id=s21625, lexunits=Profifußball), Synset(id=s133871, lexunits=Mädchenfußball), Synset(id=s137940, lexunits=Berufsfußball), Synset(id=s71210, lexunits=Jugendfußball), Synset(id=s62081, lexunits=Vereinsfußball)}\n",
      "\n",
      "relation : ConRel.has_hypernym\n",
      "{Synset(id=s21606, lexunits=Ballspiel, Ballsport, Ballsportart)}\n",
      "\n",
      "relation : ConRel.has_hyponym\n",
      "{Synset(id=s84590, lexunits=Männerfußball), Synset(id=s104374, lexunits=Spitzenfußball), Synset(id=s69685, lexunits=Amateurfußball), Synset(id=s137475, lexunits=Klubfußball), Synset(id=s139802, lexunits=Torwandschießen), Synset(id=s124051, lexunits=Freizeitfußball), Synset(id=s146603, lexunits=Straßenfußball), Synset(id=s21626, lexunits=Frauenfußball, Damenfußball), Synset(id=s79925, lexunits=Hallenfußball), Synset(id=s133731, lexunits=Weltfußball), Synset(id=s145820, lexunits=Kombinationsfußball), Synset(id=s21625, lexunits=Profifußball), Synset(id=s133871, lexunits=Mädchenfußball), Synset(id=s137940, lexunits=Berufsfußball), Synset(id=s71210, lexunits=Jugendfußball), Synset(id=s62081, lexunits=Vereinsfußball)}\n",
      "\n",
      "relation : ConRel.is_related_to\n",
      "{Synset(id=s18513, lexunits=Länderspieleinsatz), Synset(id=s20943, lexunits=Handspiel), Synset(id=s15474, lexunits=Ablöse), Synset(id=s17566, lexunits=Abseits, Abseitsposition, Abseitsstellung), Synset(id=s75887, lexunits=Schwalbe), Synset(id=s100331, lexunits=Fußballpokal), Synset(id=s10313, lexunits=Tor)}\n",
      "\n",
      "relation : ConRel.has_component_meronym\n",
      "{Synset(id=s17549, lexunits=Anstoß, Kick-off), Synset(id=s17565, lexunits=Freistoß), Synset(id=s17560, lexunits=Elfmeter, Elfer, Elfmeterschießen)}\n"
     ]
    }
   ],
   "source": [
    "print(fussball_synset.direct_hypernyms)\n",
    "print(fussball_synset.direct_hyponyms)\n",
    "for relation, synsets in fussball_synset.relations.items():\n",
    "    print(\"\\nrelation : %s\" % relation)\n",
    "    print(synsets)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see that *Fußball* has exactly one hypernym and several hyponyms. It is also possible to list all hypernyms\n",
    "from *Fußball* to the top node (root node). The level where the *Fußball* synset is attached to the Graph is called depth and\n",
    "can also be accessed. We can also check whether *Fußball* is the root or a leaf of the GermaNet graph (although of course\n",
    "we already know that this is not case, as it has both, hypernyms and hyponyms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Synset(id=s47458, lexunits=qualitative Beziehung), Synset(id=s20870, lexunits=Auseinandersetzung, Konflikt), Synset(id=s18413, lexunits=Handlung, Tat, Aktivität, Tätigkeit), Synset(id=s18275, lexunits=Sportwettkampf), Synset(id=s21606, lexunits=Ballspiel, Ballsport, Ballsportart), Synset(id=s21440, lexunits=Sport, Sportart, Disziplin, Sportdisziplin), Synset(id=s18227, lexunits=Sportveranstaltung, Sportereignis), Synset(id=s73180, lexunits=Kampf, Wettkampf), Synset(id=s13222, lexunits=Zustand), Synset(id=s17614, lexunits=Veranstaltung), Synset(id=s16557, lexunits=Geschehen, Geschehnis), Synset(id=s18348, lexunits=Spiel, Match, Partie, Sportspiel), Synset(id=s51001, lexunits=GNROOT), Synset(id=s46926, lexunits=Beziehung, Verhältnis, Relation), Synset(id=s16438, lexunits=Ereignis), Synset(id=s16437, lexunits=Situation)}\n",
      "The synset has a depth of 8 and has 16 distinct hypernyms \n",
      " is it the root node? False  \n",
      " is it a leaf node? False\n"
     ]
    }
   ],
   "source": [
    "print(fussball_synset.all_hypernyms())\n",
    "print(\"The synset has a depth of %d and has %d distinct hypernyms \\n is it the root node? %s  \\n is it a leaf node? %s\"\n",
    "      % (fussball_synset.min_depth(), len(fussball_synset.all_hypernyms()), str(fussball_synset.is_root()), str(fussball_synset.is_leaf()) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Use the semantic utils to measure semantic similarity / relatedness\n",
    "You can also use the API to compare a synset with another synset. These methods work only for two synsets that have the same word category, for example for two nouns. There are two different types of similarity measures:\n",
    "- path-based measures\n",
    "- information-content-based measures\n",
    "\n",
    "Path-based measures compute the semantic relatedness between two concepts based on the shortest path between two synsets. The shortest path is the minimal number of nodes you have to walk from the source synset to the target synset. Different measures weigh or normalize the path-length in different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "At first we will look at the simple path distance between two synsets:\n",
    "\n",
    "Let's say you would like to know how *Fußball* and *Tennis* are related within \n",
    "GermaNet. You first need to extract the synset for *Tennis*. Then you can check whether *Tennis* and *Fußball* share any \n",
    "hypernyms and print them.\n",
    "\n",
    "Finally you can extract the shortest path between Fußball and Tennis, i.e. the minimal number of \n",
    "nodes you have to walk from *Fußball* to end up at the synset of *Tennis*. You can also extract the distance between *Fußball* and \n",
    "*Tennis* (in this case the path length). Synsets that are more similar will have a shorter distance than unrelated synsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset(id=s21613, lexunits=Tennis, Tennisspiel, Tennissport)]\n",
      "{Synset(id=s16438, lexunits=Ereignis), Synset(id=s47458, lexunits=qualitative Beziehung), Synset(id=s20870, lexunits=Auseinandersetzung, Konflikt), Synset(id=s21606, lexunits=Ballspiel, Ballsport, Ballsportart), Synset(id=s18275, lexunits=Sportwettkampf), Synset(id=s21440, lexunits=Sport, Sportart, Disziplin, Sportdisziplin), Synset(id=s73180, lexunits=Kampf, Wettkampf), Synset(id=s18227, lexunits=Sportveranstaltung, Sportereignis), Synset(id=s13222, lexunits=Zustand), Synset(id=s17614, lexunits=Veranstaltung), Synset(id=s16557, lexunits=Geschehen, Geschehnis), Synset(id=s18348, lexunits=Spiel, Match, Partie, Sportspiel), Synset(id=s51001, lexunits=GNROOT), Synset(id=s46926, lexunits=Beziehung, Verhältnis, Relation), Synset(id=s18413, lexunits=Handlung, Tat, Aktivität, Tätigkeit), Synset(id=s16437, lexunits=Situation)}\n",
      "[[Synset(id=s21624, lexunits=Fußballspiel, Fußball, Fußballsport), Synset(id=s21606, lexunits=Ballspiel, Ballsport, Ballsportart), Synset(id=s21613, lexunits=Tennis, Tennisspiel, Tennissport)]]\n",
      "Fußball and Tennis have a path distance of 2\n"
     ]
    }
   ],
   "source": [
    "tennis_synsets = germanet.get_synsets_by_orthform(\"Tennis\")\n",
    "print(tennis_synsets)\n",
    "tennis_synset = tennis_synsets[0]\n",
    "print(fussball_synset.common_hypernyms(tennis_synset))\n",
    "print(fussball_synset.shortest_path(tennis_synset))\n",
    "print(\"Fußball and Tennis have a path distance of %d\" % fussball_synset.shortest_path_distance(tennis_synset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Example for path-based measures\n",
    "\n",
    "The following example shows, how to use the PathBasedRelatedness to check whether Trompete (trumpet) is more related to \n",
    "Posaune (trombone) than to Flöte (flute) and how to disambiguate Flügel (wing, blade, grand) in the context of Klavier (piano). \n",
    "\n",
    "To use the path-based semantic relatedness measures you have to create the corresponding object. This object takes the longest possible shortest distance and a Synset pair that is maximally appart as argument. If not given, those will be computed on the fly but this might take somet time, especially for nouns.\n",
    "\n",
    "As mentioned before, those measures only work for synsets that belong to the same word category, which has to be specified in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the simple path measure, is Trompete more similar to Posaune, than to Flöte? True\n",
      "\n",
      " These are the similarities between the synset for Klavier and Synset(id=s9697, lexunits=Flügel, Seitenflügel) : \n",
      " Simple Path : 0.74\n",
      " Leackock and Chodorow: 0.36\n",
      " Wu and Palmer : 0.40\n",
      "\n",
      " These are the similarities between the synset for Klavier and Synset(id=s23151, lexunits=Parteiflügel, Flügel) : \n",
      " Simple Path : 0.66\n",
      " Leackock and Chodorow: 0.28\n",
      " Wu and Palmer : 0.33\n",
      "\n",
      " These are the similarities between the synset for Klavier and Synset(id=s73683, lexunits=Flügel) : \n",
      " Simple Path : 0.69\n",
      " Leackock and Chodorow: 0.31\n",
      " Wu and Palmer : 0.35\n",
      "\n",
      " These are the similarities between the synset for Klavier and Synset(id=s12102, lexunits=Flügel, Rotorblatt) : \n",
      " Simple Path : 0.80\n",
      " Leackock and Chodorow: 0.42\n",
      " Wu and Palmer : 0.53\n",
      "\n",
      " These are the similarities between the synset for Klavier and Synset(id=s73727, lexunits=Flügel) : \n",
      " Simple Path : 0.77\n",
      " Leackock and Chodorow: 0.39\n",
      " Wu and Palmer : 0.43\n",
      "\n",
      " These are the similarities between the synset for Klavier and Synset(id=s26446, lexunits=Flügel, Schwinge) : \n",
      " Simple Path : 0.69\n",
      " Leackock and Chodorow: 0.31\n",
      " Wu and Palmer : 0.27\n",
      "\n",
      " These are the similarities between the synset for Klavier and Synset(id=s11625, lexunits=Flügel) : \n",
      " Simple Path : 0.94\n",
      " Leackock and Chodorow: 0.69\n",
      " Wu and Palmer : 0.89\n",
      "\n",
      "The most similar synset out of all synsets corresponding to the word 'Flügel' is : Synset(id=s11625, lexunits=Flügel)\n",
      "[Wictionary(LexUnit ID=l16087, definition=Musik, Musikinstrumentenbau: ein großes Klavier, besonders für Konzerte, dessen Deckel meist geöffnet ist, wenn man darauf spielt)]\n"
     ]
    }
   ],
   "source": [
    "# first, construct a path-based similarity object\n",
    "from germanetpy.path_based_relatedness_measures import PathBasedRelatedness\n",
    "johannis_wurm = germanet.get_synset_by_id(\"s49774\")\n",
    "leber_trans = germanet.get_synset_by_id(\"s83979\")\n",
    "relatedness_calculator = PathBasedRelatedness(germanet=germanet, category=WordCategory.nomen, max_len=35,\n",
    "                                             max_depth=20, synset_pair=(johannis_wurm, leber_trans))\n",
    "trompete = germanet.get_synsets_by_orthform(\"Trompete\").pop()\n",
    "flöte = germanet.get_synsets_by_orthform(\"Flöte\").pop()\n",
    "posaune = germanet.get_synsets_by_orthform(\"Posaune\").pop()\n",
    "Klavier = germanet.get_synsets_by_orthform(\"Klavier\").pop()\n",
    "Flügel_synsets = germanet.get_synsets_by_orthform(\"Flügel\")\n",
    "trompete_posaune = relatedness_calculator.simple_path(trompete, posaune)\n",
    "trompete_flöte = relatedness_calculator.simple_path(trompete, flöte)\n",
    "\n",
    "print(\"Based on the simple path measure, is Trompete more similar to Posaune, than to Flöte? %s\" % str(trompete_posaune > trompete_flöte))\n",
    "highest_sim_simple = 0.0\n",
    "highest_sim_leacock = 0.0\n",
    "highest_sim_wu = 0.0\n",
    "most_similar_synset = None\n",
    "for synset in Flügel_synsets:\n",
    "    if synset.word_category == WordCategory.nomen:\n",
    "        sim_simple = relatedness_calculator.simple_path(synset, Klavier, normalize=True)\n",
    "        sim_leacock = relatedness_calculator.leacock_chodorow(synset, Klavier, normalize=True)\n",
    "        sim_wu = relatedness_calculator.wu_and_palmer(synset, Klavier, normalize=True)\n",
    "        print(\"\\n These are the similarities between the synset for Klavier and %s : \\n Simple Path : %.2f\\n Leackock and Chodorow: %.2f\\n Wu and Palmer : %.2f\" % (str(synset), sim_simple, sim_leacock, sim_wu));\n",
    "        if sim_simple > highest_sim_simple and sim_leacock > highest_sim_leacock and sim_wu > highest_sim_wu :\n",
    "            highest_sim_simple = sim_simple\n",
    "            highest_sim_leacock = sim_leacock\n",
    "            highest_sim_wu = sim_wu\n",
    "            most_similar_synset = synset\n",
    "print(\"\\nThe most similar synset out of all synsets corresponding to the word 'Flügel' is : %s\" %str(most_similar_synset))\n",
    "print(most_similar_synset.lexunits[0].wiktionary_paraphrases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Example for IC-based measures\n",
    "\n",
    "Information-content-based measures augment the structural distances, captured by the taxonomy with word frequencies. Thus the problem of lacking uniform distances in the Graph can be reduced by providing additional information about the typicality of words. The frequencies are used to compute the information content, which graduates concepts from specific to general. If a very specific synset is compared to a very general one, the relatedness will be low. The relatedness is measured based on the information content of the lowest common subsumer (the lowest synset in the hierachy that is hypernym to both synsets that are compared to each other).\n",
    "\n",
    "To use these measures, you have to create an object that takes frequency lists as an additional argument. These lists contain the raw frequencies of the nouns, adjectives and verbs that are in Germanet, based on a very large corpus. You can eihter use the provided frequency lists or use your own lists.\n",
    "\n",
    "The following code snippet shows the advantage of the IC-based measures. While path-based measures would classify the word pair Pflanze 'plant', Tier 'animal' as bein almost as similar as the word pair Roteiche 'red oak' and Steineiche 'holm oak', the IC-based measures distinguish whether two synsets are very general or more specific and consequently assign a higher similarity score to the second word pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path-based similarity between Pflanze and Tier: 0.61, between Roteiche and Steineiche 0.69\n",
      "ic-based similarity between Pflanze and Tier: 0.11, between Roteiche and Steineiche 0.52\n"
     ]
    }
   ],
   "source": [
    "from germanetpy.icbased_similarity import ICBasedSimilarity\n",
    "relatedness_nouns = ICBasedSimilarity(germanet=germanet, wordcategory=WordCategory.nomen,\n",
    "                                          path=frequencylist_nouns)\n",
    "pflanze = germanet.get_synset_by_id(\"s44960\")\n",
    "tier = germanet.get_synset_by_id(\"s48805\")\n",
    "sim_leacock_pflanze_tier = relatedness_calculator.leacock_chodorow(pflanze, tier, normalize=True)\n",
    "roteiche = germanet.get_synset_by_id(\"s46054\")\n",
    "steineiche = germanet.get_synset_by_id(\"s46056\")\n",
    "sim_leacock_roteiche_steineiche = relatedness_calculator.leacock_chodorow(roteiche, steineiche, normalize=True)\n",
    "print(\"path-based similarity between Pflanze and Tier: %.2f, between Roteiche and Steineiche %.2f\"% (sim_leacock_pflanze_tier, sim_leacock_roteiche_steineiche))\n",
    "\n",
    "sim_resnik_pflanze_tier = relatedness_nouns.resnik(pflanze, tier, normalize=True)\n",
    "sim_resnik_roteiche_steineiche = relatedness_nouns.resnik(roteiche, steineiche, normalize=True)\n",
    "print(\"ic-based similarity between Pflanze and Tier: %.2f, between Roteiche and Steineiche %.2f\" % (sim_resnik_pflanze_tier, sim_resnik_roteiche_steineiche))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "For a more convenient search through the ontology and the semantic relatedness computation, you can use the GermaNet web application \"Rover\":\n",
    "https://weblicht.sfs.uni-tuebingen.de/rover/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Inspect Lexical Units\n",
    "Every synset contains one ore several Lexical Units. The list of Lexical Units (lexunit) can be accessed for any synset. Let's inspect the lexical units for *Fußball* 'football':\n",
    "We have the lexunit *Fußballspiel* 'football match', the lexunit *Fußball* 'football' and the lexunit *Fußballsport* 'soccer ball'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lexunit(id=l29776, orthform=Fußballspiel, synset_id=s21624), Lexunit(id=l29777, orthform=Fußball, synset_id=s21624), Lexunit(id=l29778, orthform=Fußballsport, synset_id=s21624)]\n"
     ]
    }
   ],
   "source": [
    "lexical_units_fussball = fussball_synset.lexunits\n",
    "print(lexical_units_fussball)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Every lexical unit has a number of orthographical forms. There are four different orthographical forms but not every \n",
    "lexical unit has an entry for all of them:\n",
    "* main orth. form: \n",
    "* orth. variation\n",
    "* old orth. form\n",
    "* old orth. variation\n",
    "\n",
    "We can see that the lexunit for *Fußball* only has one orth form, but that one of its related synsets *Fußballklub* 'football club' has the \n",
    "orthographical variation *Fußballkclub*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fußball'}\n",
      "{'Fußballklub', 'Fußballclub'}\n",
      "Fußballclub\n"
     ]
    }
   ],
   "source": [
    "fussball_unit = germanet.get_lexunit_by_id(\"l29777\")\n",
    "orth_forms = fussball_unit.get_all_orthforms()\n",
    "print(orth_forms)\n",
    "fussballclub_unit = germanet.get_lexunit_by_id(\"l32423\")\n",
    "orth_forms = fussballclub_unit.get_all_orthforms()\n",
    "print(orth_forms)\n",
    "print(fussballclub_unit.orthvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Fußball* is a compound, which are very frequent in the German language. GermaNet stores information about the \n",
    "compound, for example that *Fuß* 'foot' is the modifier and *ball* 'ball' is the head.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompoundInfo( modifier = Fuß, head = Ball)\n"
     ]
    }
   ],
   "source": [
    "print(fussball_unit.compound_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lexical units are related to other lexical units by different lexical relations. The most common and most general \n",
    "lexical relation is synonymy, but there are other relations annotated as well. For example, for some compounds there has been work\n",
    "on annotating the relation between the compound and the modifier. In this example the compound *Fußball* has the manner \n",
    "functioning of *Fuß*. \n",
    "\n",
    "The relations can be unidirectional (e.g. the relation \"has manner of functioning\" goes from *Fußball*\n",
    "to *Fuß*, but not the other way around. The relation can also be bidirectional, e.g. *Fußball* and *Fußballspiel* are \n",
    "synonyms of each other. If you are interested in finding out which unidirectional relations point towards *Fußball*, these\n",
    "can be accessed via \"incoming_relations\":\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {<LexRel.has_synonym: 'has_synonym'>: {Lexunit(id=l29778, orthform=Fußballsport, synset_id=s21624), Lexunit(id=l29776, orthform=Fußballspiel, synset_id=s21624)}, <LexRel.has_manner_of_functioning: 'has_manner_of_functioning'>: {Lexunit(id=l35740, orthform=Fuß, synset_id=s26149)}})\n",
      "defaultdict(<class 'set'>, {<LexRel.has_pertainym: 'has_pertainym'>: {Lexunit(id=l4226, orthform=fußballerisch, synset_id=s2869)}, <LexRel.has_specialization: 'has_specialization'>: {Lexunit(id=l53360, orthform=Fußballamateur, synset_id=s37146)}, <LexRel.has_active_usage: 'has_active_usage'>: {Lexunit(id=l13796, orthform=Fußballstadion, synset_id=s9891), Lexunit(id=l10294, orthform=Fußballschuh, synset_id=s7143)}, <LexRel.has_topic: 'has_topic'>: {Lexunit(id=l88379, orthform=Fußballschule, synset_id=s63191)}})\n"
     ]
    }
   ],
   "source": [
    "print(fussball_unit.relations)\n",
    "print(fussball_unit.incoming_relations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some lexical units have sense definitions, harvested from the German Wictionary. These can be accessed with the wiktionary_paraphrases field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Wictionary(LexUnit ID=l29777, definition=Sport, Freizeit, kein Plural: eine beliebte Mannschaftssportart, welche mit 22 Spielern und einem Ball gespielt wird)]\n"
     ]
    }
   ],
   "source": [
    "print(fussball_unit.wiktionary_paraphrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some lexical units have also been linked to the English WordNet. The can be accessed with the ili_records field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IliRecord(LexUnit ID=l29777, relation=synonym, english_equivalent=association football)]\n"
     ]
    }
   ],
   "source": [
    "print(fussball_unit.ili_records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lexical units which are verbs provide information on language use by giving at least one example sentence.\n",
    "They are also annotated with subcategorisation patterns / verb complementations (frames). It is possible to extract\n",
    "verbs with specific complements of interest, for example if you're interested in all verbs that allow accusative complements\n",
    "you can extract them with specific methods, defined in the frames class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexunit(id=l80272, orthform=schießen, synset_id=s56962)\n",
      "['Er hatte den Ball ins Tor geschossen.']\n",
      "['NN.AN.BD']\n",
      "There are  11735 verbs that can take an accusative complement in GermaNet \n",
      " An example of such is: Lexunit(id=l84327, orthform=einstanzen, synset_id=s59971) \n",
      " Another example is : Lexunit(id=l74428, orthform=bringen, synset_id=s52726)\n"
     ]
    }
   ],
   "source": [
    "schiessen = germanet.get_lexunit_by_id(\"l80272\")\n",
    "print(schiessen)\n",
    "print(schiessen.examples)\n",
    "print(schiessen.frames)\n",
    "f = Frames(germanet.frames2lexunits)\n",
    "all_verbs_with_accusative_complement = f.extract_accusative_complemtent()\n",
    "print(\"There are  %d verbs that can take an accusative complement in GermaNet \\n An example of such is: %s \\n Another example is : %s\"\n",
    "      % (len(all_verbs_with_accusative_complement), all_verbs_with_accusative_complement.pop(), all_verbs_with_accusative_complement.pop()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## How to extract a large number of examples by applying a filter function\n",
    "If you would like to extract several lexical units or synsets from GermaNet that fulfill a certain number of \n",
    "conditions you can create a filter configuration. A filter configuration allows you for example to search for words of specific\n",
    "Word Classes (e.g. you might be interested in extracting all abstract nouns) or you would like to extract all words that \n",
    "contain a specific subword. To do a search you have to create a filter configuration object. You have to pass a search string\n",
    "as an argument. All other options have defaults but you can set them to adapt your search. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered result\n",
      "Synset(id=s60205, lexunits=erlegen, schießen)\n",
      "Synset(id=s59153, lexunits=knipsen, schießen)\n",
      "Synset(id=s56650, lexunits=schießen)\n",
      "Synset(id=s21555, lexunits=Schießen, Schießsport, Sportschießen)\n",
      "Synset(id=s57998, lexunits=stürmen, stürzen, schießen)\n",
      "Synset(id=s123485, lexunits=schießen)\n",
      "Synset(id=s56664, lexunits=schießen)\n",
      "Synset(id=s56962, lexunits=schießen)\n",
      "\n",
      "filtered result\n",
      "Synset(id=s56650, lexunits=schießen) WordClass.Konkurrenz\n",
      "Synset(id=s56664, lexunits=schießen) WordClass.Konkurrenz\n",
      "\n",
      "filtered result\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# we can search for \"schuss\" but we don't want to care about upper or lowercasing and about different orthforms:\n",
    "filterconfig = Filterconfig(\"schießen\", ignore_case=True)\n",
    "result = filterconfig.filter_synsets(germanet)\n",
    "print(\"filtered result\")\n",
    "for word in result:\n",
    "    print(word)\n",
    "# Let's say we are only interested in synsets of a specific semantic class:\n",
    "filterconfig.word_classes = [WordClass.Konkurrenz]\n",
    "result = filterconfig.filter_synsets(germanet)\n",
    "print(\"\\nfiltered result\")\n",
    "for word in result:\n",
    "    print(word, word.word_class)\n",
    "# if we now filter by word category and use only nouns, our result will be empty because there is not entry for 'schießen' as a noun:\n",
    "filterconfig.word_categories = [WordCategory.nomen]\n",
    "result = filterconfig.filter_synsets(germanet)\n",
    "print(\"\\nfiltered result\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Besides using full words as search strings we can use regular expressions. This can be very useful if you are interested \n",
    "in words with certain character sequences. The next examples shows how to extract all words that end with \"kuchen\", all \n",
    "words that contain a whitespace or hyphen (useful for example to extract multiword expressions) and how to extract verbs that contain\n",
    "'ff' or 'ss':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  54 words that end with 'kuchen' in GermaNet \n",
      " An example of such is: Lexunit(id=l58659, orthform=Gemüsekuchen, synset_id=s40018) \n",
      " Another example is : Lexunit(id=l173751, orthform=Spritzkuchen, synset_id=s132941)\n",
      "\n",
      "Found  5419 multiword expressions with whitespace or hypen in GermaNet \n",
      " An example of such is: Lexunit(id=l179864, orthform=Livebericht, synset_id=s103961) \n",
      " Another example is : Lexunit(id=l151444, orthform=Doppel-LP, synset_id=s114428)\n",
      "\n",
      "Found  974 verbs with double s or double f in GermaNet \n",
      " An example of such is: Lexunit(id=l110632, orthform=missinterpretieren, synset_id=s54976) \n",
      " Another example is : Lexunit(id=l141908, orthform=dressieren, synset_id=s106785)\n"
     ]
    }
   ],
   "source": [
    "# extract all words that end with 'kuchen'\n",
    "filterconfig = Filterconfig('.*kuchen', regex=True)\n",
    "filterconfig.word_categories = [WordCategory.nomen]\n",
    "result = filterconfig.filter_lexunits(germanet)\n",
    "print(\"Found  %d words that end with 'kuchen' in GermaNet \\n An example of such is: %s \\n Another example is : %s\"\n",
    "      % (len(result), result.pop(), result.pop()))\n",
    "\n",
    "# extract all words that contain a white space or a hyphen\n",
    "filterconfig = Filterconfig('.+(\\s|-).+', regex=True)\n",
    "filterconfig.word_categories = [WordCategory.nomen]\n",
    "result = filterconfig.filter_lexunits(germanet)\n",
    "print(\"\\nFound  %d multiword expressions with whitespace or hypen in GermaNet \\n An example of such is: %s \\n Another example is : %s\"\n",
    "      % (len(result), result.pop(), result.pop()))\n",
    "\n",
    "# extract all verbs that contain exactly two 'ss' or two 'ff'\n",
    "filterconfig = Filterconfig('.+(f{2,}|s{2,}).+', regex=True)\n",
    "filterconfig.word_categories = [WordCategory.verben]\n",
    "result = filterconfig.filter_lexunits(germanet)\n",
    "print(\"\\nFound  %d verbs with double s or double f in GermaNet \\n An example of such is: %s \\n Another example is : %s\"\n",
    "      % (len(result), result.pop(), result.pop()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (germaNetPy)",
   "language": "python",
   "name": "pycharm-4f820cd9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
